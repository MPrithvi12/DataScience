# -*- coding: utf-8 -*-
"""FRAUD DETECTION SYSTEM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P5202_MwJZ4L2geQCjYPeXUaNX9akk22

#**IMPORTING LIBRARIES**#
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""#**loading the dataset to a Pandas Dataframe**#"""

abc_bank_data = pd.read_csv('/content/Data Anaytics Project Data .csv')

"""#**first five rows of the dataset**#"""

abc_bank_data.head()

abc_bank_data.info()

"""#**checking the number of missing values in each column**#"""

abc_bank_data.isnull().sum

"""#**distribution of legit transaction & fraudlent transaction**#"""

abc_bank_data['Is_Fraudulent'].value_counts()

"""#**This dataset is highly unbalanced**#
#**0 >- Normal Transaction**#
#**1 >- Fraudulent Transaction**#
"""

#separating the data for analysis
legit = abc_bank_data[abc_bank_data.Is_Fraudulent == 0]
fraud = abc_bank_data[abc_bank_data.Is_Fraudulent == 1]

print(legit.shape)
print(fraud.shape)

# statistical measures of the data
legit.Transaction_Amount.describe()

fraud.Transaction_Amount.describe()

# compare the values for legit and fraud transaction
abc_bank_data.groupby('Is_Fraudulent').mean()

"""#**Under-Sampleing**#

#**Build a sample dataset containing similar distribution of normal transactions and Fraudulent Transactions**#

**Number of Fraudulent Transactions --> 8
"""

legit_sample = legit.sample(n=8)

"""Concatenating two data frames"""

new_dataset = pd.concat([legit_sample, fraud], axis=0)

new_dataset.head()

new_dataset['Is_Fraudulent'].value_counts()

new_dataset.groupby('Is_Fraudulent').mean()

"""Spliting data into features and targets"""

X = new_dataset.drop(columns='Is_Fraudulent', axis=1)
Y = new_dataset['Is_Fraudulent']

print(X)

print(Y)

"""Spliting the data into Training data and Test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape,X_test.shape)

"""Model Training"""